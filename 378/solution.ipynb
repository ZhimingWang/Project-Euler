{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The idea is simple: calculate all $\\mathrm{dT}(j)$, then for each $j$ calculate the number of $i$s s.t. $i < j$ and $\\mathrm{dT}(i) > \\mathrm{dT}(j)$ and the number of $k$s s.t. $k > j$ and $\\mathrm{dT}(j) < \\mathrm{dT}(k)$. To calculate these we need a binary search tree that can tell us the current number of elements smaller (or greater) than the element being inserted.\n",
    "\n",
    "I used full factorizations to calculate $\\mathrm{dT}$, which cost me >2min and 5GB in memory. In hindsight, sieving to obtain $d(j)$ for all $j <= N+1$ then use $d(j(j+1)/2) = d(j/2)d(j+1)$ for even $j$ and $d(j)d((j+1)/2)$ for odd $j$ is probably way faster due to the lack of lookup and allocations.\n",
    "\n",
    "For the binary search tree part, obviously STL doesn't cut it, and I've forgotten all about algorithms, so I ended up reinventing a shitty variant of [binary indexed tree](https://en.wikipedia.org/wiki/Fenwick_tree) where each node keeps track of the size of the subtree with it at the root."
   ]
  }
 ]
}